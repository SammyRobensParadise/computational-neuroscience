{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reinforcement Learning Mouse Model of Maze Discovery\n",
        "\n",
        "SYDE 552\n",
        "\n",
        "Winter 2023\n",
        "\n",
        "April 21st 2023\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing neccesary libraries for data creation and visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "cuygndk_FToF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD , Adam, RMSprop\n",
        "from keras.layers.activation import PReLU\n",
        "from random import randint\n",
        "import os, sys, time, datetime, json, random"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code for simulating a rat in a maze with actions, agent and reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "twcMVfZlGkKv"
      },
      "outputs": [],
      "source": [
        "# dcreate the colors\n",
        "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
        "mouse_mark = 0.5  # The current rat cell will be painteg by gray 0.5\n",
        "\n",
        "# numerically assign valus to possible actions\n",
        "# assume rat cannot move diagonal\n",
        "LEFT = 0\n",
        "UP = 1\n",
        "RIGHT = 2\n",
        "DOWN = 3\n",
        "\n",
        "# Actions dictionary\n",
        "actions_dict: dict[int, str] = {\n",
        "    LEFT: \"left\",\n",
        "    UP: \"up\",\n",
        "    RIGHT: \"right\",\n",
        "    DOWN: \"down\",\n",
        "}\n",
        "\n",
        "num_actions: int = len(actions_dict)\n",
        "\n",
        "# Exploration factor\n",
        "#  one of every 10 moves the agent takes a completely random action\n",
        "epsilon: float = 1 / 10\n",
        "\n",
        "\n",
        "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
        "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
        "# mouse = (row, col) initial mouse position (defaults to (0,0))\n",
        "\n",
        "\n",
        "class Qmaze(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        maze: list,\n",
        "        mouse: list = (0, 0),\n",
        "        valid_penalty: float = -0.04,\n",
        "        invalid_penality: float = -0.75,\n",
        "        visited_penality: float = -0.25,\n",
        "    ):\n",
        "        self._maze = np.array(maze)\n",
        "        nrows, ncols = self._maze.shape\n",
        "        self._valid_penality = valid_penalty\n",
        "        self._invalid_penality = invalid_penality\n",
        "        self._visited_penality = visited_penality\n",
        "\n",
        "        # target cell where the \"cheese\" is\n",
        "        # the default behaviour is that the cheese is always in the\n",
        "        # bottom right corner of the maze\n",
        "        self.target = (nrows - 1, ncols - 1)\n",
        "\n",
        "        # create free cells\n",
        "        self.free_cells = [\n",
        "            (r, c)\n",
        "            for r in range(nrows)\n",
        "            for c in range(ncols)\n",
        "            if self._maze[r, c] == 1.0\n",
        "        ]\n",
        "        # remove the target from the \"free cells\"\n",
        "        self.free_cells.remove(self.target)\n",
        "\n",
        "        # throw an exception if there is no way to get to the target cell\n",
        "        if self._maze[self.target] == 0.0:\n",
        "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
        "\n",
        "        # throw an exception if the mouse is not started on a free cell\n",
        "        if not mouse in self.free_cells:\n",
        "            raise Exception(\"Invalid mouse Location: must sit on a free cell\")\n",
        "        self.reset(mouse)\n",
        "\n",
        "    def reset(self, mouse):\n",
        "        self.mouse = mouse\n",
        "        self.maze = np.copy(self._maze)\n",
        "        _, _ = self.maze.shape\n",
        "        row, col = mouse\n",
        "        self.maze[row, col] = mouse_mark\n",
        "        self.state = (row, col, \"start\")\n",
        "        self.min_reward = -0.5 * self.maze.size\n",
        "        self.total_reward = 0\n",
        "        self.visited = set()\n",
        "\n",
        "    def update_state(self, action):\n",
        "        _, _ = self.maze.shape\n",
        "        nrow, ncol, nmode = mouse_row, mouse_col, mode = self.state\n",
        "\n",
        "        if self.maze[mouse_row, mouse_col] > 0.0:\n",
        "            self.visited.add((mouse_row, mouse_col))  # mark visited cell\n",
        "\n",
        "        valid_actions = self.valid_actions()\n",
        "\n",
        "        if not valid_actions:\n",
        "            nmode = \"blocked\"\n",
        "        elif action in valid_actions:\n",
        "            nmode = \"valid\"\n",
        "            if action == LEFT:\n",
        "                ncol -= 1\n",
        "            elif action == UP:\n",
        "                nrow -= 1\n",
        "            if action == RIGHT:\n",
        "                ncol += 1\n",
        "            elif action == DOWN:\n",
        "                nrow += 1\n",
        "        else:  # invalid action, no change mouse position\n",
        "            mode = \"invalid\"\n",
        "\n",
        "        # new state\n",
        "        self.state = (nrow, ncol, nmode)\n",
        "\n",
        "    def get_reward(self):\n",
        "        mouse_row, mouse_col, mode = self.state\n",
        "        nrows, ncols = self.maze.shape\n",
        "        valid_penalty = self._valid_penality\n",
        "        invalid_penalty = self._invalid_penality\n",
        "        visited_penalty = self._visited_penality\n",
        "        if mouse_row == nrows - 1 and mouse_col == ncols - 1:\n",
        "            return 1.0\n",
        "        if mode == \"blocked\":\n",
        "            return self.min_reward - 1\n",
        "        if (mouse_row, mouse_col) in self.visited:\n",
        "            return visited_penalty\n",
        "        if mode == \"invalid\":\n",
        "            return invalid_penalty\n",
        "        if mode == \"valid\":\n",
        "            return valid_penalty\n",
        "\n",
        "    def act(self, action):\n",
        "        self.update_state(action)\n",
        "        reward = self.get_reward()\n",
        "        self.total_reward += reward\n",
        "        print(self.total_reward)\n",
        "        status = self.trial_status()\n",
        "        env_state = self.observe()\n",
        "        return env_state, reward, status\n",
        "\n",
        "    def observe(self):\n",
        "        canvas = self.create_environment()\n",
        "        env_state = canvas.reshape((1, -1))\n",
        "        return env_state\n",
        "\n",
        "    def create_environment(self):\n",
        "        canvas = np.copy(self.maze)\n",
        "        nrows, ncols = self.maze.shape\n",
        "        # clear all visual marks\n",
        "        for r in range(nrows):\n",
        "            for c in range(ncols):\n",
        "                if canvas[r, c] > 0.0:\n",
        "                    canvas[r, c] = 1.0\n",
        "        # draw the mouse\n",
        "        row, col, valid = self.state\n",
        "        canvas[row, col] = mouse_mark\n",
        "        return canvas\n",
        "\n",
        "    def trial_status(self):\n",
        "        if self.total_reward < self.min_reward:\n",
        "            return \"lose\"\n",
        "        mouse_row, mouse_col, mode = self.state\n",
        "        nrows, ncols = self.maze.shape\n",
        "        if mouse_row == nrows - 1 and mouse_col == ncols - 1:\n",
        "            return \"win\"\n",
        "        return \"not_over\"\n",
        "\n",
        "    def valid_actions(self, cell=None):\n",
        "        if cell is None:\n",
        "            row, col, _ = self.state\n",
        "        else:\n",
        "            row, col = cell\n",
        "        actions = [0, 1, 2, 3]\n",
        "        nrows, ncols = self.maze.shape\n",
        "        if row == 0:\n",
        "            actions.remove(1)\n",
        "        elif row == nrows - 1:\n",
        "            actions.remove(3)\n",
        "\n",
        "        if col == 0:\n",
        "            actions.remove(0)\n",
        "        elif col == ncols - 1:\n",
        "            actions.remove(2)\n",
        "\n",
        "        if row > 0 and self.maze[row - 1, col] == 0.0:\n",
        "            actions.remove(1)\n",
        "        if row < nrows - 1 and self.maze[row + 1, col] == 0.0:\n",
        "            actions.remove(3)\n",
        "\n",
        "        if col > 0 and self.maze[row, col - 1] == 0.0:\n",
        "            actions.remove(0)\n",
        "        if col < ncols - 1 and self.maze[row, col + 1] == 0.0:\n",
        "            actions.remove(2)\n",
        "\n",
        "        return actions\n",
        "\n",
        "\n",
        "# show 8x8 maze | WALL = BLACK | MOUSE = DARK GRAY | PATH = LIGHT GRAY | CHEESE = VERY LIGHT GRAY\n",
        "def show(qmaze: Qmaze):\n",
        "    plt.grid(\"on\")\n",
        "    nrows, ncols = qmaze.maze.shape\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
        "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    canvas = np.copy(qmaze.maze)\n",
        "    for row, col in qmaze.visited:\n",
        "        canvas[row, col] = 0.6\n",
        "    mouse_row, mouse_col, _ = qmaze.state\n",
        "    canvas[mouse_row, mouse_col] = 0.3  # mouse cell\n",
        "    canvas[nrows - 1, ncols - 1] = 0.9  # cheese cell\n",
        "    img = plt.imshow(canvas, interpolation=\"none\", cmap=\"gray\")\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Random Maze\n",
        "\n",
        "Applying Depth First Search (DFS) to generate random maze based on entrance and exit (aka cheese) location adapted from https://www.geeksforgeeks.org/random-acyclic-maze-generator-with-given-entry-and-exit-point/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8WZ-PWIUTe3",
        "outputId": "6ab0e5b0-d016-4ea2-d1fc-605fd23bed79"
      },
      "outputs": [],
      "source": [
        "# Class to define structure of a node\n",
        "class Node:\n",
        "    def __init__(self, value=None, next_element=None):\n",
        "        self.val = value\n",
        "        self.next = next_element\n",
        "\n",
        "\n",
        "# Class to implement a stack\n",
        "class stack:\n",
        "    # Constructor\n",
        "    def __init__(self):\n",
        "        self.head = None\n",
        "        self.length = 0\n",
        "\n",
        "    # Put an item on the top of the stack\n",
        "    def insert(self, data):\n",
        "        self.head = Node(data, self.head)\n",
        "        self.length += 1\n",
        "\n",
        "    # Return the top position of the stack\n",
        "    def pop(self):\n",
        "        if self.length == 0:\n",
        "            return None\n",
        "        else:\n",
        "            returned = self.head.val\n",
        "            self.head = self.head.next\n",
        "            self.length -= 1\n",
        "            return returned\n",
        "\n",
        "    # Return False if the stack is empty\n",
        "    # and true otherwise\n",
        "    def not_empty(self):\n",
        "        return bool(self.length)\n",
        "\n",
        "    # Return the top position of the stack\n",
        "    def top(self):\n",
        "        return self.head.val\n",
        "\n",
        "\n",
        "def generate_random_maze(\n",
        "    rows: int = 8,\n",
        "    columns: int = 8,\n",
        "    initial_point: list = (0, 0),\n",
        "    final_point: list = (7, 7),\n",
        "):\n",
        "    ROWS, COLS = rows, columns\n",
        "\n",
        "    # Array with only walls (where paths will\n",
        "    # be created)\n",
        "    maze = list(list(0 for _ in range(COLS)) for _ in range(ROWS))\n",
        "\n",
        "    # Auxiliary matrices to avoid cycles\n",
        "    seen = list(list(False for _ in range(COLS)) for _ in range(ROWS))\n",
        "    previous = list(list((-1, -1) for _ in range(COLS)) for _ in range(ROWS))\n",
        "\n",
        "    S = stack()\n",
        "\n",
        "    # Insert initial position\n",
        "    S.insert(initial_point)\n",
        "\n",
        "    # Keep walking on the graph using dfs\n",
        "    # until we have no more paths to traverse\n",
        "    # (create)\n",
        "    while S.not_empty():\n",
        "        # Remove the position of the Stack\n",
        "        # and mark it as seen\n",
        "        x, y = S.pop()\n",
        "        seen[x][y] = True\n",
        "\n",
        "        # This is to avoid cycles with adj positions\n",
        "        if (x + 1 < ROWS) and maze[x + 1][y] == 1 and previous[x][y] != (x + 1, y):\n",
        "            continue\n",
        "        if (0 < x) and maze[x - 1][y] == 1 and previous[x][y] != (x - 1, y):\n",
        "            continue\n",
        "        if (y + 1 < COLS) and maze[x][y + 1] == 1 and previous[x][y] != (x, y + 1):\n",
        "            continue\n",
        "        if (y > 0) and maze[x][y - 1] == 1 and previous[x][y] != (x, y - 1):\n",
        "            continue\n",
        "\n",
        "        # Mark as walkable position\n",
        "        maze[x][y] = 1\n",
        "\n",
        "        # Array to shuffle neighbours before\n",
        "        # insertion\n",
        "        to_stack = []\n",
        "\n",
        "        # Before inserting any position,\n",
        "        # check if it is in the boundaries of\n",
        "        # the maze\n",
        "        # and if it were seen (to avoid cycles)\n",
        "\n",
        "        # If adj position is valid and was not seen yet\n",
        "        if (x + 1 < ROWS) and seen[x + 1][y] == False:\n",
        "            # Mark the adj position as seen\n",
        "            seen[x + 1][y] = True\n",
        "\n",
        "            # Memorize the position to insert the\n",
        "            # position in the stack\n",
        "            to_stack.append((x + 1, y))\n",
        "\n",
        "            # Memorize the current position as its\n",
        "            # previous position on the path\n",
        "            previous[x + 1][y] = (x, y)\n",
        "\n",
        "        if (0 < x) and seen[x - 1][y] == False:\n",
        "            # Mark the adj position as seen\n",
        "            seen[x - 1][y] = True\n",
        "\n",
        "            # Memorize the position to insert the\n",
        "            # position in the stack\n",
        "            to_stack.append((x - 1, y))\n",
        "\n",
        "            # Memorize the current position as its\n",
        "            # previous position on the path\n",
        "            previous[x - 1][y] = (x, y)\n",
        "\n",
        "        if (y + 1 < COLS) and seen[x][y + 1] == False:\n",
        "            # Mark the adj position as seen\n",
        "            seen[x][y + 1] = True\n",
        "\n",
        "            # Memorize the position to insert the\n",
        "            # position in the stack\n",
        "            to_stack.append((x, y + 1))\n",
        "\n",
        "            # Memorize the current position as its\n",
        "            # previous position on the path\n",
        "            previous[x][y + 1] = (x, y)\n",
        "\n",
        "        if (y > 0) and seen[x][y - 1] == False:\n",
        "            # Mark the adj position as seen\n",
        "            seen[x][y - 1] = True\n",
        "\n",
        "            # Memorize the position to insert the\n",
        "            # position in the stack\n",
        "            to_stack.append((x, y - 1))\n",
        "\n",
        "            # Memorize the current position as its\n",
        "            # previous position on the path\n",
        "            previous[x][y - 1] = (x, y)\n",
        "\n",
        "        # Indicates if Pf is a neighbour position\n",
        "        pf_flag = False\n",
        "        while len(to_stack):\n",
        "            # Remove random position\n",
        "            neighbour = to_stack.pop(randint(0, len(to_stack) - 1))\n",
        "\n",
        "            # Is the final position,\n",
        "            # remember that by marking the flag\n",
        "            if neighbour == final_point:\n",
        "                pf_flag = True\n",
        "\n",
        "            # Put on the top of the stack\n",
        "            else:\n",
        "                S.insert(neighbour)\n",
        "\n",
        "        # This way, Pf will be on the top\n",
        "        if pf_flag:\n",
        "            S.insert(final_point)\n",
        "\n",
        "    # Mark the initial position\n",
        "    x0, y0 = initial_point\n",
        "    xf, yf = final_point\n",
        "    maze[x0][y0] = 1\n",
        "    maze[xf][yf] = 1\n",
        "\n",
        "    # Return maze formed by the traversed path\n",
        "    return np.asarray(maze, dtype=\"float\")\n",
        "\n",
        "\n",
        "# Test Run to ensure that function is working correctly\n",
        "test_cols = 8\n",
        "test_rows = 8\n",
        "test_init_point = (0, 0)\n",
        "test_final_point = (7, 7)\n",
        "\n",
        "test_maze = generate_random_maze(\n",
        "    rows=test_rows,\n",
        "    columns=test_cols,\n",
        "    initial_point=test_init_point,\n",
        "    final_point=test_final_point,\n",
        ")\n",
        "# check that the shape generated is correct\n",
        "assert test_maze.shape == (test_cols, test_rows)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating a maze array and initializing a Qmaze\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "EdFkyj_YGCEE",
        "outputId": "fd51aaac-dedd-41e4-c9f1-a37f5a22c35e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x168ce6bb0>"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "maze = generate_random_maze(8, 8, (0, 0), (7, 7))\n",
        "qmaze = Qmaze(maze=maze)\n",
        "show(qmaze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    def __init__(self, maze, learning_rate: float = 0.001):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(maze.size, input_shape=(maze.size,)))\n",
        "        model.add(PReLU())\n",
        "        model.add(Dense(maze.size))\n",
        "        model.add(PReLU())\n",
        "        model.add(Dense(num_actions))\n",
        "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "        self.model = model\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Trial\n",
        "\n",
        "Create an `Trial` class that accepts a trained neural network which calculates the next action, a Qmaze and the initial cell that the mouse is in.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trial:\n",
        "    def __init__(self, model: Model, qmaze: Qmaze, mouse_cell: list):\n",
        "        self._qmaze = qmaze\n",
        "        self._model = model\n",
        "        self.mouse_cell = mouse_cell\n",
        "\n",
        "    def run(self):\n",
        "        mouse_cell = self._get_mouse_cell()\n",
        "        self._qmaze.reset(mouse_cell)\n",
        "        env_state = self._qmaze.observe()\n",
        "        while True:\n",
        "            prev_env_state = env_state\n",
        "            Q = self._model.get_model().predict(prev_env_state)\n",
        "            action = np.argmax(Q[0])\n",
        "            _, _, status = self._qmaze.act(action)\n",
        "            if status == \"win\":\n",
        "                return True\n",
        "            elif status == \"lose\":\n",
        "                return False\n",
        "\n",
        "    # For small mazes we can allow ourselves to perform a completion check in which we simulate all possible\n",
        "    # games and check if our model wins the all. This is not practical for large mazes as it slows down training.\n",
        "    def check(self):\n",
        "        self._qmaze = self._get_maze()\n",
        "        for cell in self._qmaze.free_cells:\n",
        "            if not self._qmaze.valid_actions(cell):\n",
        "                return False\n",
        "            if not self.run():\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def _get_maze(self):\n",
        "        return self._qmaze\n",
        "\n",
        "    def _get_model(self):\n",
        "        return self._model\n",
        "\n",
        "    def _get_mouse_cell(self):\n",
        "        return self.mouse_cell"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Class to Model the Experience of the Mouse\n",
        "\n",
        "Create an `Experience` class that collects the experience of `Experiments` within a `list` of memory. It retreives a `model`, a `max_memory` which defines the maximum amount of experiments that the mouse can _remember_ and a `discount` factor which represents the instantanious uncertainty in the _Bellman equation for stochastic environments_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Experience(object):\n",
        "    def __init__(self, model: Model, max_memory: int = 8, discount: float = 95 / 100):\n",
        "        self.model = model\n",
        "        self.max_memory = max_memory\n",
        "        self.discount = discount\n",
        "        self.memory = list()\n",
        "        self.actions = model.get_model().output_shape[-1]\n",
        "\n",
        "    def remember(self, trial):\n",
        "        self.memory.append(trial)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            # delete the first element of the memory list if we exceed the max memory\n",
        "            del self.memory[0]\n",
        "\n",
        "    def predict(self, env_state):\n",
        "        return self.model.get_model().predict(env_state)[0]\n",
        "\n",
        "    def data(self, data_size: int = 10):\n",
        "        environment_size = self.memory[0][0].shape[1]\n",
        "        memory_size = len(self.memory)\n",
        "        data_size = min(memory_size, data_size)\n",
        "        inputs = np.zeros((data_size, environment_size))\n",
        "        targets = np.zeros((data_size, self.actions))\n",
        "        for idx, jdx in enumerate(\n",
        "            np.random.choice(range(memory_size), data_size, replace=False)\n",
        "        ):\n",
        "            env_state, action, reward, env_state_next, trial_over = self.memory[jdx]\n",
        "            inputs[idx] = env_state\n",
        "            # There should be no target values for actions not taken.\n",
        "            targets[idx] = self.predict(env_state)\n",
        "            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n",
        "            Q_sa = np.max(self.predict(env_state_next))\n",
        "            if trial_over:\n",
        "                targets[idx, action] = reward\n",
        "            else:\n",
        "                # reward + gamma * max_a' Q(s', a')\n",
        "                targets[idx, action] = reward + self.discount * Q_sa\n",
        "        return inputs, targets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q-Training Algorithm for Reinforcement Learning of Mouse\n",
        "The algorithm accepts the a `number_epoch` which is the number of epochs, the maximum memory `max_memory` which is the maximum number of trials kept in memory and the `data_size` which is the number of  samples in training epoch. This is the number of trials randomly selected from the mouse's experience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a small utility for printing readable time strings:\n",
        "def format_time(seconds):\n",
        "    if seconds < 400:\n",
        "        s = float(seconds)\n",
        "        return \"%.1f seconds\" % (s,)\n",
        "    elif seconds < 4000:\n",
        "        m = seconds / 60.0\n",
        "        return \"%.2f minutes\" % (m,)\n",
        "    else:\n",
        "        h = seconds / 3600.0\n",
        "        return \"%.2f hours\" % (h,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Experiment(object):\n",
        "    def __init__(self, maze=generate_random_maze(), model_learning_rate: int = 0.001):\n",
        "        qmaze = Qmaze(maze)\n",
        "        model = Model(maze, learning_rate=model_learning_rate)\n",
        "        trial = Trial(model, qmaze, (0, 0))\n",
        "        self.qmaze = qmaze\n",
        "        self.model = model\n",
        "        self.trial = trial\n",
        "\n",
        "    def train(self, **opt):\n",
        "        print(\"training....\")\n",
        "        global epsilon\n",
        "        number_epoch = opt.get(\"epochs\", 15000)\n",
        "        max_memory = opt.get(\"max_memory\", 1000)\n",
        "        data_size = opt.get(\"data_size\", 50)\n",
        "        name = opt.get(\"name\", \"model\")\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # Initialize experience replay object\n",
        "        experience = Experience(self.model, max_memory=max_memory)\n",
        "\n",
        "        completion_history = []  # history of win/lose game\n",
        "        number_free_cells = len(self.qmaze.free_cells)\n",
        "        hsize = self.qmaze.maze.size // 2  # history window size\n",
        "        win_rate = 0.0\n",
        "        imctr = 1\n",
        "\n",
        "        for epoch in range(number_epoch):\n",
        "            loss = 0.0\n",
        "            mouse_cell = random.choice(self.qmaze.free_cells)\n",
        "            self.qmaze.reset(mouse_cell)\n",
        "            trial_over = False\n",
        "\n",
        "            # get initial env_state (1d flattened canvas)\n",
        "            env_state = self.qmaze.observe()\n",
        "\n",
        "            n_trials = 0\n",
        "            while not trial_over:\n",
        "                valid_actions = self.qmaze.valid_actions()\n",
        "                if not valid_actions:\n",
        "                    break\n",
        "                prev_env_state = env_state\n",
        "                # Get next action\n",
        "                if np.random.rand() < epsilon:\n",
        "                    print(\"random\")\n",
        "                    action = random.choice(valid_actions)\n",
        "                else:\n",
        "                    print(\"predict\")\n",
        "                    action = np.argmax(experience.predict(prev_env_state))\n",
        "\n",
        "                # Apply action, get reward and new env_state\n",
        "                print(action)\n",
        "                env_state, reward, status = self.qmaze.act(action)\n",
        "                print(\"status\")\n",
        "                print(status)\n",
        "                print(\"reward\")\n",
        "                print(reward)\n",
        "                print(env_state)\n",
        "                if status == \"win\":\n",
        "                    completion_history.append(1)\n",
        "                    trial_over = True\n",
        "                elif status == \"lose\":\n",
        "                    completion_history.append(0)\n",
        "                    trial_over = True\n",
        "                else:\n",
        "                    trial_over = False\n",
        "\n",
        "                # Store trial (experience)\n",
        "                trial = [prev_env_state, action, reward, env_state, trial_over]\n",
        "                experience.remember(trial)\n",
        "                n_trials += 1\n",
        "\n",
        "                # Train neural network model\n",
        "                inputs, targets = experience.data(data_size=data_size)\n",
        "                _ = self.model.get_model().fit(\n",
        "                    inputs,\n",
        "                    targets,\n",
        "                    epochs=8,\n",
        "                    batch_size=16,\n",
        "                    verbose=0,\n",
        "                )\n",
        "                loss = self.model.get_model().evaluate(inputs, targets, verbose=0)\n",
        "\n",
        "            if len(completion_history) > hsize:\n",
        "                win_rate = sum(completion_history[-hsize:]) / hsize\n",
        "\n",
        "            dt = datetime.datetime.now() - start_time\n",
        "            t = format_time(dt.total_seconds())\n",
        "            template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Trials: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n",
        "            print(\n",
        "                template.format(\n",
        "                    epoch,\n",
        "                    number_epoch - 1,\n",
        "                    loss,\n",
        "                    n_trials,\n",
        "                    sum(completion_history),\n",
        "                    win_rate,\n",
        "                    t,\n",
        "                )\n",
        "            )\n",
        "            # we simply check if training has exhausted all free cells and if in all\n",
        "            # cases the agent won\n",
        "            if win_rate > 0.9:\n",
        "                epsilon = 0.05\n",
        "            if sum(completion_history[-hsize:]) == hsize and self.trial.check():\n",
        "                print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n",
        "                break\n",
        "\n",
        "        # Save trained model weights and architecture, this will be used by the visualization code\n",
        "        h5file = name + \".h5\"\n",
        "        json_file = name + \".json\"\n",
        "        self.model.get_model().save_weights(h5file, overwrite=True)\n",
        "        with open(json_file, \"w\") as outfile:\n",
        "            json.dump(self.model.get_model().to_json(), outfile)\n",
        "        end_time = datetime.datetime.now()\n",
        "        dt = datetime.datetime.now() - start_time\n",
        "        seconds = dt.total_seconds()\n",
        "        t = format_time(seconds)\n",
        "        print(\"files: %s, %s\" % (h5file, json_file))\n",
        "        print(\n",
        "            \"n_epoch: %d, max_mem: %d, data: %d, time: %s\"\n",
        "            % (epoch, max_memory, data_size, t)\n",
        "        )\n",
        "        return seconds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training....\n",
            "predict\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "0\n",
            "-0.25\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  1.  0.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "0\n",
            "-0.5\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  1.  0.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1\n",
            "-0.54\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.04\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1\n",
            "-0.79\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "0\n",
            "-0.8300000000000001\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.04\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1\n",
            "-1.08\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2\n",
            "-1.33\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "2\n",
            "-1.58\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "0\n",
            "-1.83\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "0\n",
            "-2.08\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "2\n",
            "-2.33\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "random\n",
            "3\n",
            "-2.58\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  1.  0.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "2\n",
            "-2.83\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  1.  0.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "2\n",
            "-3.08\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  1.  0.  1.  1.  1.  1.  0.  0.  0.5 0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "random\n",
            "1\n",
            "-3.33\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1\n",
            "-3.58\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1\n",
            "-3.83\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[1.  0.5 0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "0\n",
            "-4.08\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3\n",
            "-4.33\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3\n",
            "-4.58\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "predict\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "0\n",
            "-4.83\n",
            "status\n",
            "not_over\n",
            "reward\n",
            "-0.25\n",
            "[[0.5 1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.\n",
            "  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.\n",
            "  1.  0.  1.  0.  0.  1.  1.  1.  0.  1. ]]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m experiment\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, max_memory\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m \u001b[39m*\u001b[39;49m maze\u001b[39m.\u001b[39;49msize, data_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
            "\u001b[1;32m/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb Cell 19\u001b[0m in \u001b[0;36mExperiment.train\u001b[0;34m(self, **opt)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m n_trials \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# Train neural network model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m inputs, targets \u001b[39m=\u001b[39m experience\u001b[39m.\u001b[39;49mdata(data_size\u001b[39m=\u001b[39;49mdata_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_model()\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     inputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_model()\u001b[39m.\u001b[39mevaluate(inputs, targets, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[1;32m/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb Cell 19\u001b[0m in \u001b[0;36mExperience.data\u001b[0;34m(self, data_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m targets[idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(env_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m Q_sa \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(env_state_next))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m trial_over:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     targets[idx, action] \u001b[39m=\u001b[39m reward\n",
            "\u001b[1;32m/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb Cell 19\u001b[0m in \u001b[0;36mExperience.predict\u001b[0;34m(self, env_state)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, env_state):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sammyrobens-paradise/projects/computational-neuroscience/project/reinforcement-mouse-learning.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_model()\u001b[39m.\u001b[39;49mpredict(env_state)[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2342\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2343\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2347\u001b[0m         )\n\u001b[0;32m-> 2349\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2350\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2351\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2352\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2353\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2354\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2355\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2356\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2357\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2358\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2359\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2360\u001b[0m )\n\u001b[1;32m   2362\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1261\u001b[0m     x,\n\u001b[1;32m   1262\u001b[0m     y,\n\u001b[1;32m   1263\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1264\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1265\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1266\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1267\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1268\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1269\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1270\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1271\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1272\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1275\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py:307\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    302\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    310\u001b[0m     \u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2242\u001b[0m     map_func,\n\u001b[1;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:113\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m--> 113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39;49m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs,\n\u001b[1;32m    116\u001b[0m     f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction,\n\u001b[1;32m    117\u001b[0m     use_inter_op_parallelism\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_inter_op_parallelism,\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[1;32m    120\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(input_dataset, variant_tensor)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3459\u001b[0m, in \u001b[0;36mmap_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[1;32m   3457\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3458\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3459\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3460\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMapDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, input_dataset, other_arguments, \u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m, f,\n\u001b[1;32m   3461\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes,\n\u001b[1;32m   3462\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39muse_inter_op_parallelism\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_inter_op_parallelism,\n\u001b[1;32m   3463\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mpreserve_cardinality\u001b[39;49m\u001b[39m\"\u001b[39;49m, preserve_cardinality, \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m, metadata)\n\u001b[1;32m   3464\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3465\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "experiment = Experiment()\n",
        "\n",
        "experiment.train(epochs=1000, max_memory=8 * maze.size, data_size=32)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
